%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Installation}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.\@ }}
\makeatletter
\def\fnum@figure{\figurename\thefigure{}}
\makeatother
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\makeatletter
\def\fnum@table{\tablename\thetable{}}
\makeatother
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{diapysef Documentation}
\date{Mar 13, 2019}
\release{}
\author{RÃ¶st Lab}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


diapysef is a convenience package for working with DIA-PASEF data. It has
functionalities to convert Bruker raw files into a format that OpenMS can
understand. Thus OpenSwath can be used to analyze the data and TOPPView can
\begin{quote}

be used to visualize.
\end{quote}

The diapysef package contains python bindings for the processing and analysis
of mass spectrometry data coupled to TIMS-TOF based proteomics. It provides
open-source access to algorithms specifically designed for DIA (data-
independent acquisition) experiments. These bindings include algorithms that
allow conversions of raw data (Bruker tdf.d), generation of spectral library,
basic signal-processing (compression, filtering), and simple visualization
of the raw data.

Note: The current documentation relates to the 0.3.3 version of diapysef.
Note: Please acquire the Bruker tdf-sdk through official distributions.


\chapter{Data Access}
\label{\detokenize{convenientfunctions:data-access}}\label{\detokenize{convenientfunctions::doc}}
After installation of diapysef and all of its dependencies, make sure that the
Bruker sdk file is in your current working directory, and you should be able
to import the package or call the scripts.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{diapysef}
\end{sphinxVerbatim}

should import all the functions in diapysef, which allows access to the tdf data.

Succefully importing diapysef should result in the following output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Found} \PYG{n}{Bruker} \PYG{n}{sdk}\PYG{o}{.} \PYG{n}{Access} \PYG{n}{to} \PYG{n}{the} \PYG{n}{raw} \PYG{n}{data} \PYG{o+ow}{is} \PYG{n}{possible}\PYG{o}{.}
\end{sphinxVerbatim}

Otherwise, if it results in:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Bruker} \PYG{n}{sdk} \PYG{o+ow}{not} \PYG{n}{found}\PYG{o}{.} \PYG{n}{Some} \PYG{n}{functionalities} \PYG{n}{that} \PYG{n}{need} \PYG{n}{access} \PYG{n}{to} \PYG{n}{raw} \PYG{n}{data} \PYG{n}{will}
\PYG{o+ow}{not} \PYG{n}{be} \PYG{n}{available}\PYG{o}{.} \PYG{n}{To} \PYG{n}{activate} \PYG{n}{that} \PYG{n}{functionality} \PYG{n}{place} \PYG{n}{libtimsdata}\PYG{o}{.}\PYG{n}{so} \PYG{p}{(}\PYG{n}{Linux}\PYG{p}{)}
\PYG{o+ow}{or} \PYG{n}{timsdata}\PYG{o}{.}\PYG{n}{dll} \PYG{o+ow}{in} \PYG{n}{the} \PYG{n}{src} \PYG{n}{folder}\PYG{o}{.}
\end{sphinxVerbatim}

Please put a the Bruker sdk file in the working directory or make a symlink.


\section{Getting Help}
\label{\detokenize{convenientfunctions:getting-help}}
To get more detailed description of the available functions in diapysef, you can use
the python function \sphinxcode{\sphinxupquote{help}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{diapysef}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{help}\PYG{p}{(}\PYG{n}{diapysef}\PYG{p}{)}
\PYG{g+gp}{...}
\PYG{g+gp}{...}
\end{sphinxVerbatim}


\chapter{Data Structure}
\label{\detokenize{convenientfunctions:data-structure}}
The functions of diapysef can either be used in a python shell, or directly executed
as a commandline tool.

diapysef is able to read directly into the sqlite-based .tdf raw files and store
information about the acquisition methods.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{diapysef} \PYG{k}{as} \PYG{n+nn}{dp}
\PYG{n}{dia} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{TimsData}\PYG{p}{(}\PYG{n}{pasefdata}\PYG{p}{)}
\PYG{n}{win} \PYG{o}{=} \PYG{n}{dia}\PYG{o}{.}\PYG{n}{get\PYGZus{}windows}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{win}\PYG{o}{.}\PYG{n}{to\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{window\PYGZus{}layout.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{File Written}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

Alternatively, the function can be called directly in command line.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{get\PYGZus{}dia\PYGZus{}windows}\PYG{o}{.}\PYG{n}{py} \PYG{n}{pasefdata} \PYG{n}{outputfile}
\end{sphinxVerbatim}

With our pipeline using MaxQuant DDA data for our spectral library generation, we need
to convert the ion mobility units to 1/K0 values for standardized measure. The MaxQuant
output files evidence and all\_peptides have ion mobility values in scan numbers, which
correspond to the ion mobility 1/K0 values.

Converting the scan numbers to 1/K0 values require a raw .tdf file that contains the
calibration information.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{diapysef} \PYG{k}{as} \PYG{n+nn}{dp}
\PYG{n}{pas} \PYG{o}{=} \PYG{n}{dp}\PYG{o}{.}\PYG{n}{PasefData}\PYG{p}{(}\PYG{n}{pasefdata}\PYG{p}{)}
\PYG{n}{mq} \PYG{o}{=} \PYG{n}{dp}\PYG{o}{.}\PYG{n}{PasefMQData}\PYG{p}{(}\PYG{n}{MQout\PYGZus{}directory}\PYG{p}{)}

\PYG{n}{mq}\PYG{o}{.}\PYG{n}{get\PYGZus{}all\PYGZus{}peptides}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{mq}\PYG{o}{.}\PYG{n}{annotate\PYGZus{}ion\PYGZus{}mobilitty}\PYG{p}{(}\PYG{n}{pas}\PYG{p}{)}
\PYG{n}{all\PYGZus{}pep} \PYG{o}{=} \PYG{n}{mq}\PYG{o}{.}\PYG{n}{all\PYGZus{}peptides}
\PYG{n}{all\PYGZus{}pep}\PYG{o}{.}\PYG{n}{to\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{all\PYGZus{}peptides\PYGZus{}1K0.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{mq}\PYG{o}{.}\PYG{n}{get\PYGZus{}evidence}
\PYG{n}{mq}\PYG{o}{.}\PYG{n}{annotate\PYGZus{}ion\PYGZus{}mobility}\PYG{p}{(}\PYG{n}{pas}\PYG{p}{)}
\PYG{n}{ev} \PYG{o}{=} \PYG{n}{mq}\PYG{o}{.}\PYG{n}{evidence}
\PYG{n}{ev}\PYG{o}{.}\PYG{n}{to\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{evidence\PYGZus{}1K0.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

Alternative, these functions can be called in command line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{annotate\PYGZus{}mq\PYGZus{}ionmobility}\PYG{o}{.}\PYG{n}{py} \PYG{n}{MQOUT\PYGZus{}director} \PYG{n}{Pasefdata} \PYG{n}{output\PYGZus{}prefix}
\end{sphinxVerbatim}

The above function writes a simple csv file that contains information of the pasef run
including isolation window width, isolation window starts and ends, ion mobility drift
time starts and ends, collision energy, etc. With these information, we can plot the
window placements in the dimensions of m/z and ion mobility.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{diapysef} \PYG{k}{as} \PYG{n+nn}{dp}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{n}{dia} \PYG{o}{=} \PYG{n}{dp}\PYG{o}{.}\PYG{n}{TimsData}\PYG{p}{(}\PYG{n}{pasefdata}\PYG{p}{)}
\PYG{n}{win} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{window\PYGZus{}layout.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{dp}\PYG{o}{.}\PYG{n}{plot\PYGZus{}window\PYGZus{}layout}\PYG{p}{(}\PYG{n}{windows} \PYG{o}{=} \PYG{n}{win}\PYG{p}{)}
\end{sphinxVerbatim}

If you have a MaxQuant output of the library precursors, you can also map the precursors
with the windows.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{diapysef} \PYG{k}{as} \PYG{n+nn}{dp}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{n}{dia} \PYG{o}{=} \PYG{n}{dp}\PYG{o}{.}\PYG{n}{TimsData}\PYG{p}{(}\PYG{n}{pasefdata}\PYG{p}{)}
\PYG{n}{win} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{window\PYGZus{}layout.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{precursors} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{all\PYGZus{}peptides.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{dp}\PYG{o}{.}\PYG{n}{plot\PYGZus{}window\PYGZus{}layout}\PYG{p}{(}\PYG{n}{windows} \PYG{o}{=} \PYG{n}{win}\PYG{p}{,} \PYG{n}{precursor\PYGZus{}map} \PYG{o}{=} \PYG{n}{precursors}\PYG{p}{)}
\end{sphinxVerbatim}

Or alternatively, the function can be called in command line.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}dia\PYGZus{}windows}\PYG{o}{.}\PYG{n}{py} \PYG{n}{window\PYGZus{}layout}\PYG{o}{.}\PYG{n}{csv} \PYG{n}{annotated\PYGZus{}all\PYGZus{}peptides\PYGZus{}1K0}\PYG{o}{.}\PYG{n}{csv}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
Precursor map is the allPeptides.csv file generated from MaxQuant and needs to be
properly annotated with 1/K0 values.
\end{sphinxadmonition}


\chapter{Data Visualization}
\label{\detokenize{datavisualization:data-visualization}}\label{\detokenize{datavisualization::doc}}
Other than using the \sphinxcode{\sphinxupquote{plot\_window\_layout}} function in the package, the
data can also be visualized using OpenMS tools after conversion to mzML files.

OpenMS 2.4.0 version is capable of visualizing data with ion mobility values.
Using \sphinxcode{\sphinxupquote{ToppView}}, you can now visualize the four dimensional data through
slicing it by retention time and look at the MS spectrum.

\noindent\sphinxincludegraphics{{imview}.PNG}

This displays the map at retention time 4479 seconds, the features in a 2D map
with ion mobility and m/z. Switching it into 3D view, you can see the intensity
of the precursors.

\noindent\sphinxincludegraphics{{im3dview}.PNG}

OpenMS is now capable of handling ion mobility data with all of its previous
usages remained functional.


\chapter{Library Generation}
\label{\detokenize{librarygeneration:library-generation}}\label{\detokenize{librarygeneration::doc}}
For most data-independent acquisition (DIA) analysis, a well-represented
spectral library is required for precursors, peptide, and protein
identifications. Currently, we acquire our library through using deeply
fractionated sample runs that are analyzed in MaxQuant.

The general steps for generating the spectral library are, annotating ion
mobility values in the MQ output, correcting retention time and ion mobilty
values against iRT peptides, formatting it to OpenSwath read-able format,
generate the spectral library formats (.TraML, .pqp, .tsv) with OpenSwath.


\section{Annotating Ion Mobility}
\label{\detokenize{librarygeneration:annotating-ion-mobility}}
Generating the library requires the DDA output files from MaxQuant.
* msms.txt
* allPeptides.txt
* evidence.txt

Before generating the assay library, the ion mobility values have to be
converted from scan numbers in MaxQuant output to the standardized 1/K0
units.

Follow the instructions at :doc: \sphinxtitleref{convenientfunctions} for annotating
and writing out files with standardized units.


\section{Correcting RT and IM values}
\label{\detokenize{librarygeneration:correcting-rt-and-im-values}}
For correcting the retention time and ion mobility values, an iRT peptide
library file including ion mobility dimension is required. Having the
MaxQuant output directory (annotated with ion mobiltiy 1/K0) and iRT file,
we can generate an OpenSwath readable format of library.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{diapysef} \PYG{k}{as} \PYG{n+nn}{dp}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{c+c1}{\PYGZsh{} read in the MQOUT files}
\PYG{n}{msms} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mqout\PYGZus{}dir/msms.txt}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sep} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} read in the annotated evidence file}
\PYG{n}{evidence} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mqout\PYGZus{}dir/annotated\PYGZus{}evidence.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{irt} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{irt\PYGZus{}file.tsv}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Alignment of RT and IM values}
\PYG{n}{ptsv} \PYG{o}{=} \PYG{n}{dp}\PYG{o}{.}\PYG{n}{pasef\PYGZus{}to\PYGZus{}tsv}\PYG{p}{(}\PYG{n}{evidence}\PYG{p}{,} \PYG{n}{msms}\PYG{p}{,} \PYG{n}{irt\PYGZus{}file} \PYG{o}{=} \PYG{n}{irt}\PYG{p}{,} \PYGZbs{}
\PYG{n}{im\PYGZus{}column}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{IonMobilityIndexK0}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{rt\PYGZus{}alignment}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{nonlinear}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{im\PYGZus{}alignment}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{linear}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} save the library table}
\PYG{n}{ptsv}\PYG{o}{.}\PYG{n}{to\PYGZus{}csv}\PYG{p}{(}\PYG{n}{ptsv}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mqout.tsv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sep} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{index} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{)}
\end{sphinxVerbatim}

The function allows a few options for the alignment of retention time and ion
mobility values. The input \sphinxcode{\sphinxupquote{rt\_alignment}} has options for \sphinxcode{\sphinxupquote{nonlinear}} for a
lowess alignment, \sphinxcode{\sphinxupquote{linear}} alignment, and \sphinxcode{\sphinxupquote{None}}. For \sphinxcode{\sphinxupquote{im\_alignment}}, it
contains options of \sphinxcode{\sphinxupquote{linear}} or \sphinxcode{\sphinxupquote{None}}. For standard LC-MS/MS analysis, we
suggest alignment using \sphinxcode{\sphinxupquote{nonlinear}} for \sphinxcode{\sphinxupquote{rt\_alignment}} and \sphinxcode{\sphinxupquote{linear}} for
\sphinxcode{\sphinxupquote{im\_alignment}}.

Alternatively, we also have a script as a commandline tool that can be called with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{create\PYGZus{}library}\PYG{o}{.}\PYG{n}{py}
\end{sphinxVerbatim}

For details and options of the script, simply type:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{create\PYGZus{}library}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{help}
\end{sphinxVerbatim}


\section{Generating Assay Library}
\label{\detokenize{librarygeneration:generating-assay-library}}
After generating the library with corrected retention time and ion mobility values,
a standardized assay library can be generated through OpenSwath applications.


\subsection{Standardize Assay Library}
\label{\detokenize{librarygeneration:standardize-assay-library}}
First, the library table can be converted into standard assay formats (.TraML, .pqp, .tsv)
using \sphinxcode{\sphinxupquote{OpenSwathAssayGenerator}}.


\subsection{Inputs}
\label{\detokenize{librarygeneration:inputs}}
\sphinxcode{\sphinxupquote{OpenSwathAssayGenerator}} requires several inputs parameters.
\textendash{} \sphinxcode{\sphinxupquote{in}} : Input file of library transitions
\textendash{} \sphinxcode{\sphinxupquote{out}}: Output file with valid extensions
\textendash{} \sphinxcode{\sphinxupquote{swath\_windows\_file}}: File contains isolation window information

An example would be this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{OpenSwathAssayGenerator} \PYG{o}{\PYGZhy{}}\PYG{o+ow}{in} \PYG{n}{mqout}\PYG{o}{.}\PYG{n}{tsv} \PYG{o}{\PYGZhy{}}\PYG{n}{out} \PYG{n}{hela\PYGZus{}assaylib}\PYG{o}{.}\PYG{n}{TraML} \PYGZbs{}
                        \PYG{o}{\PYGZhy{}}\PYG{n}{swath\PYGZus{}windows\PYGZus{}file} \PYG{n}{window\PYGZus{}setting}\PYG{o}{.}\PYG{n}{txt}
\end{sphinxVerbatim}


\subsection{Generate Decoy}
\label{\detokenize{librarygeneration:generate-decoy}}
The assay library can add decoy peptides for statistical validation of scores
and identification. It can be done through \sphinxcode{\sphinxupquote{OpenSwathDecoyGenerator}}.


\subsection{Inputs}
\label{\detokenize{librarygeneration:id1}}
\sphinxcode{\sphinxupquote{OpenSwathDecoyGenerator}} requires several input parameters.
\textendash{} \sphinxcode{\sphinxupquote{in}}: Input file of the target assay library
\textendash{} \sphinxcode{\sphinxupquote{out}}: Output file of the target-decoy library
\textendash{} \sphinxcode{\sphinxupquote{method}}: Method of generating the decoy
\textendash{} \sphinxcode{\sphinxupquote{switchKR}}: Boolean of switching the termini of the decoy peptides

An example would be this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{OpenSwathDecoyGenerator} \PYG{o}{\PYGZhy{}}\PYG{o+ow}{in} \PYG{n}{hela\PYGZus{}assaylib}\PYG{o}{.}\PYG{n}{TraML} \PYGZbs{}
                        \PYG{o}{\PYGZhy{}}\PYG{n}{out} \PYG{n}{hela\PYGZus{}target\PYGZus{}decoy\PYGZus{}assaylib}\PYG{o}{.}\PYG{n}{TraML} \PYGZbs{}
                        \PYG{o}{\PYGZhy{}}\PYG{n}{method} \PYG{n}{pseudo}\PYG{o}{\PYGZhy{}}\PYG{n}{reverse} \PYGZbs{}
                        \PYG{o}{\PYGZhy{}}\PYG{n}{switchKR} \PYG{n}{true}
\end{sphinxVerbatim}

After generating the target decoy library, the assay library file is ready for the
input for \sphinxcode{\sphinxupquote{OpenSwathWorkflow}} parameter, \sphinxcode{\sphinxupquote{tr}}.


\chapter{Data Conversion}
\label{\detokenize{dataconversion:data-conversion}}\label{\detokenize{dataconversion::doc}}
The generated .tdf files from DIA pasef runs can be converted to standard
formats (mzML) with diapysef.

Using the script \sphinxcode{\sphinxupquote{convertTDFtoMzML.py}} can convert the .tdf file to
a single mzML file. It allows merging of frames for the same precursors,
filtering of range of frames, splitting of files by overlapping window
settings, and compression of data with PyMSNumpress.


\section{Inputs}
\label{\detokenize{dataconversion:inputs}}
\textendash{} \sphinxcode{\sphinxupquote{-a}}: Analysis directory of the raw data (.d) (Required)
\textendash{} \sphinxcode{\sphinxupquote{-o}}: Output filename (Required)
\textendash{} \sphinxcode{\sphinxupquote{-m}}: Number of frames for merging
\textendash{} \sphinxcode{\sphinxupquote{-overlap}}: Number of overlapping windows
\textendash{} \sphinxcode{\sphinxupquote{-r}}: Range of frames to convert

For detailed options and descriptions, simple type:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{convertTDFtoMzML}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{help}
\end{sphinxVerbatim}


\section{Example}
\label{\detokenize{dataconversion:example}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
data\PYGZus{}dir=diaPasef\PYGZus{}run.d
output\PYGZus{}file=\PYGZsq{}diaPasef\PYGZus{}run.mzML\PYGZsq{}

convertTDFtoMzML.py \PYGZhy{}a=\PYGZdl{}data\PYGZus{}dir \PYGZhy{}o=\PYGZdl{}output\PYGZus{}file
\end{sphinxVerbatim}

The converted mzML files can be processed with the assay library in \sphinxcode{\sphinxupquote{OpenSwathWorkflow}}.


\chapter{Quantification and Identification}
\label{\detokenize{openswath:quantification-and-identification}}\label{\detokenize{openswath::doc}}
Using the assay library and the mzML files, identification and quantification of peptides
can be performed with \sphinxcode{\sphinxupquote{OpenSwathWorkflow}} and \sphinxcode{\sphinxupquote{PyProphet}}. For detailed description
and documentation of the downstream analysis, please refer to \sphinxhref{http://openswath.org/en/latest/docs/binaries.html}{their documentation website}. The newest \sphinxcode{\sphinxupquote{OpenMS}} version 2.4.0
includes functionalities in handling ion mobility informations. Here are some of the
input parameters that are additional to the regular parameters.


\section{Inputs}
\label{\detokenize{openswath:inputs}}
\textendash{} \sphinxcode{\sphinxupquote{-ion\_mobility\_window}}: Ion mobility extraction window of precursor
\textendash{} \sphinxcode{\sphinxupquote{-im\_extraction\_window\_ms1}}: Use ion mobility on MS1 level
\textendash{} \sphinxcode{\sphinxupquote{-irt\_im\_extraction\_window}}: iRT extraction of the ion mobilty correction values
\textendash{} \sphinxcode{\sphinxupquote{-use\_ms1\_ion\_mobility}}: Performs extraction on MS1 level ion mobility level
\textendash{} \sphinxcode{\sphinxupquote{-Calibration:ms1\_im\_calibration}}: Use ms1 for ion mobility calibration
\textendash{} \sphinxcode{\sphinxupquote{-Calibration:im\_correction\_function}}: Choose im correction function
\textendash{} \sphinxcode{\sphinxupquote{-Calibration:debug\_im\_file}}: Record the ion mobility correction data
\textendash{} \sphinxcode{\sphinxupquote{-Scoring:Scores:use\_ion\_mobility\_scores}}: Add ion mobility for scoring


\section{Output}
\label{\detokenize{openswath:output}}
\sphinxcode{\sphinxupquote{OpenSwathWorkflow}} can generate \sphinxcode{\sphinxupquote{.tsv}}, \sphinxcode{\sphinxupquote{.osw}} for identification and scorign output. It
is also capable of generating the chromatogram files with extension \sphinxcode{\sphinxupquote{.sqmass}}. The quantified
output \sphinxcode{\sphinxupquote{.tsv}} and \sphinxcode{\sphinxupquote{.osw}} can be statistically validated with \sphinxcode{\sphinxupquote{PyProphet}}.


\section{Statistical Validation}
\label{\detokenize{openswath:statistical-validation}}
\sphinxcode{\sphinxupquote{PyProphet}} can take the scores generated from \sphinxcode{\sphinxupquote{OpenSwathWorkflow}} and statistically validate
the precursor identifications. For detailed documentation, please refer to \sphinxhref{http://openswath.org/en/latest/docs/binaries.html\#pyprophet}{the website}.


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\end{itemize}


\section{Acknowledgements}
\label{\detokenize{index:acknowledgements}}
The tools and workflows are collaboratively developed with the data acquired
by the \sphinxhref{https://www.biochem.mpg.de/en/rd/mann}{Mann Group at MPI, Bremen} ,
the \sphinxhref{http://www.imsb.ethz.ch/research/aebersold.html}{Aebersold Group at IMSB, ETH Zurich},
and Bruker Daltonics. The core pipeline is also referenced from \sphinxhref{http://www.openms.org}{OpenMS}
and \sphinxhref{https://github.com/PyProphet}{PyProphet}, and \sphinxhref{https://github.com/msproteomicstools}{msproteomicstools}.



\renewcommand{\indexname}{Index}
\printindex
\end{document}